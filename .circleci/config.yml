version: 2.1

# Think of orbs as libraries or packages for CircleCI
orbs:
  slack: circleci/slack@4.5.0
  aws-cli: circleci/aws-cli@2.0.6
  aws-eks: circleci/aws-eks@2.0.0
  browser-tools: circleci/browser-tools@1.2.3
  kubernetes: circleci/kubernetes@1.0.2
  docker: circleci/docker@2.0.1

# These are custom functions that I use in other jobs
commands:
  # Function 1
  notify_slack_error:
    steps:
      - slack/notify:
          event: fail
          template: basic_fail_1 # build in formating template to display failure
          mentions: "@ugochi" #if you want to target a particular person
          channel: alerts # Slack channel to display to

  # Function 2
  rollback-container-build:
    description: Rollback of Container Build to last working image
    parameters:
      # Add parameter here
      docker_image_tag:
        type: string
    steps:
      - checkout
      - run:
          name: Destroy Docker Image
          when: on_fail
          command: |
            # Your code here
            echo "Rolling back latest container to last working container"
            # Revert to previous container as the latest.
            # Delete the new container
            exit 1

  # Function 3
  cleanup-eks:
    description: Clean-up and destroy EKS cluster
    parameters:
      cluster-name:
        type: string
    steps:
      - checkout
      - run:
          name: Undeploy Applications
          when: on_fail
          command: |
            echo "Undeploying Applications"
            cd kubernetes
            kubectl delete -f dagster-service.yaml --namespace=production
            kubectl delete -f dagster-deployment.yaml --namespace=production
            kubectl delete -f dagster-service-account.yaml --namespace=production
            kubectl delete -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml --namespace=production
            exit 1

      - run: 
          name: Delete Cluster
          when: on_fail
          command: |
            echo "Deleting Cluster"
            eksctl delete cluster --name=<<parameters.cluster-name>> --namespace production
            exit 1

jobs:
  lint:
    docker: 
      # This image has poetry, pyenv, pip, pipenv, and python 3.10 pre-installed
      # https://hub.docker.com/r/cimg/python
      - image: cimg/python:3.9.7  
    steps:
      - checkout
      # Use the chown command to grant CircleCI access to dependency locations
      - run: sudo chown -R circleci:circleci /usr/local/bin
      - restore_cache:
          keys:
          - v1-dependencies-{{ checksum "pyproject.toml" }}
          # fallback to using the latest cache if no exact match is found, so checksum failed
          - v1-dependencies-
      - run:
          name: Install Tools & Dependencies
          command: |
            
            # Create Environment
            python -m venv capstone
            . capstone/bin/activate
            echo -e "VIRTUAL_ENV=${VIRTUAL_ENV}\n"

            # Check linux operating system of docker container
            cat /etc/os-release

            # install tools
            make setup

            # Install python packages
            make pip-install

            make lint

      - save_cache:
          name: Save Python Virtualenv Dependencies
          key: v1-dependencies-{{ checksum "pyproject.toml" }}
          paths:
            - /usr/local/bin # Binaries of dependencies
            - capstone

      #- slack/notify # I need to add a SLACK TOKEN to enable this.
  
  # Making sure unittest pass
  test_code:
    docker: 
      # This image has poetry, pyenv, pip, pipenv, and python 3.10 pre-installed
      # https://hub.docker.com/r/cimg/python
      - image: cimg/python:3.9.7
    steps:
      - checkout
      # Use the chown command to grant CircleCI access to dependency locations
      - run: sudo chown -R circleci:circleci /usr/local/bin
      - restore_cache:
          keys:
          - v1-dependencies-{{ checksum "pyproject.toml" }}
          # fallback to using the latest cache if no exact match is found
          - v1-dependencies-
    
      - run: 
          name: Activate Environment
          command: |
            . capstone/bin/activate
            echo -e "VIRTUAL_ENV=${VIRTUAL_ENV}\n"
            pip list

      # I have to activate the virtual environment to get his to work.
      - run:
          name: Run Dagster Tests
          command: |
            . capstone/bin/activate # Why would I need to do this again?
            make test
      #- slack/notify # I need to add a SLACK TOKEN to enable this.

  # Build container and make sure browser test passes
  # More about URL servers
  build-and-deploy-image:
    docker:
      - image: cimg/python:3.9.7
    working_directory: ~/project/dagster
    environment:
      VERSION: v.1.<<pipeline.number>>
    steps:
      - checkout
      
      - aws-cli/install # Works only for python images, need install python 
      - docker/install-docker-tools
      - setup_remote_docker

      - run:
          name: Print Operating System
          command: |
            # Check linux operating system of docker container
            cat /etc/os-release

      - run:
          name: Load Docker image Layer Cache
          command: |
            # The following command says, if you want the command to fail due to an error at any stage 
            # when pipe(|) output of a command to another command
            set +o pipefail 
            docker load -i /caches/dagster-app.tar | true

      - run: 
          name: Build and Test Dagster Images
          command: |
            
            cd dagster

            # Your stack command code here
            echo "Building image..."

            echo "VERSION=${VERSION}"
            ls -l

            echo "DOCKER COMPOSE UP"
            docker-compose -f docker-compose-prod.yml up -d --force-recreate --build 

            echo "See images that are built"
            docker images

            echo "See containers running"
            docker ps

            echo "Stop Containers"
            docker-compose -f docker-compose-prod.yml down
            docker ps
            docker images 

            echo "@@@Push to Repository"
            docker login -u $DOCKER_USERNAME -p $DOCKER_ACCESS_CODE
            docker tag $DOCKER_USERNAME/dagit:$VERSION $DOCKER_USERNAME/dagit:latest
            docker image push  $DOCKER_USERNAME/dagit:$VERSION
            docker image push $DOCKER_USERNAME/dagit:latest

  #Jobs for Continuous Deployment          
  create-cluster:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
    steps:
      - checkout
      - kubernetes/install
      - run: 
          name: Install eksctl
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
            sudo mv /tmp/eksctl /usr/local/bin
            eksctl version
      #- aws-eks/install-aws-iam-authenticator
      - run: 
          name: Install AWS IAM Authenticator
          command: |
            curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.21.2/2021-07-05/bin/linux/amd64/aws-iam-authenticator
      
      - run: 
          name: Create Cluster
          command: |
            #cd kubernetes
            #eksctl create cluster -f dagster-cluster.yaml

            # Reference: https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html
            eksctl create cluster \
            --name <<parameters.cluster-name>> \
            --region $AWS_DEFAULT_REGION \
            --fargate #optional

      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: <<parameters.cluster-name>>
          install-aws-cli: false
          aws-region: $AWS_DEFAULT_REGION

      - run:
          name: View Kubernetes Resources
          command: |
            echo "@@@ Nodes"
            kubectl get nodes -o wide

            #echo -e "\n@@@ Services"
            #kubectl get services

            echo "@@@ Pods"
            kubectl get pods --all-namespaces -o wide

      # Destroy cluster on fail
      - run:
          name: Delete Cluster
          command: |
            # This take approximately 15 minutes to complete
            # View progress on Cloudformation console
            eksctl delete cluster --name=<<parameters.cluster-name>> --wait=true
          when: on_fail

  # Reference:
  # https://circleci.com/docs/2.0/configuration-cookbook/#using-amazon-elastic-container-service-for-kubernetes-amazon-eks 
  # https://circleci.com/developer/orbs/orb/circleci/kubernetes#usage-deployment
  eks-deploy-resources:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
    working_directory: ~/project/kubernetes
    steps:
      - checkout
      - aws-cli/install
      - kubernetes/install-kubectl
      # TO DO: Create yaml files that describe the resource
      # Create Stateful Deployment Resource
      # Create Service Resource
      - run:
          name: Change Namespace
          command: |
            kubectl create ns production

      # Reference: https://stackoverflow.com/questions/49032812/how-to-pull-image-from-dockerhub-in-kubernetes
      - run: 
          name: Deploy Metric Server
          command: |
            kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml --namespace=production
            kubectl get deployment metrics-server -n kube-system

      - run: 
          name: Link DockerHub repo to EKS
          command: |
            kubectl create secret docker-registry regcred \
            --docker-username=$DOCKER_USERNAME \
            --docker-password=$DOCKER_ACCESS_CODE \
            --docker-email=$DOCKER_EMAIL \
            --namespace=production
      - run: 
          name: Create Service Account in Cluster
          command: |
            kubectl apply -f dagster-service-account.yaml --namespace=production

      - run: 
          name: Check Service Account is created
          command: |
            kubectl get sa production-service-account --namespace=production

      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: kubernetes/dagster-deployment.yaml # path in git directory
          resource-name: deployment/dagster-deployment.yaml # <Type of Resource>/<Name>
          show-kubectl-command: true
          watch-rollout-status: true
          namespace: production
      
      - run: 
          name: Check Pods and Service are created
          command: |
            cd kubernetes
            kubectl get pods --namespace=production
            kubectl get services --namespace=production
            kubectl describe pods

      - run: 
          name: Expose to the public through load balancer
          command: |
            kubectl expose deployment dagster-deployment \
            --namespace=production \
            --type=LoadBalancer \
            --name=dagster-service

            kubectl get service/dagster-service --namespace=production
      #Using your browser, navigate to the DNS endpoint specified in the EXTERNAL-IP 
      # Destroy cluster on fail
      - cleanup-eks:
          cluster-name: <<parameters.cluster-name>>
            

# Workflows
# ----------------------
workflows:
  deployment:
    jobs:
      - lint

      - test_code:
          requires: [lint] # I need the dependencies to be created first
      
      - build-and-deploy-image:
          requires: [test_code]

      # END OF CONTINUOUS INTEGRATION, START CONTINUOUS DELIVERY
      # - create-cluster:
      #     cluster-name: dagster-eks          
      #     requires:
      #       - build-and-deploy-image 
      #     filters:
      #        branches:
      #          only: [main, develop, uj_deploy]
      
      # Create EKS cluster (if not already created)
      # It also creates the default VPC for the cluster
      # Reference: https://eksctl.io/usage/vpc-networking/
      - aws-eks/create-cluster:
          cluster-name: dagster-eks
          show-eksctl-command: true
          aws-region: $AWS_DEFAULT_REGION
          tags: "Owner=UgochiJ,application=udacity-app,purpose=learning"
          requires:
            - build-and-deploy-image 
          filters:
             branches:
               only: [main, develop, uj_deploy]

      - eks-deploy-resources:
          cluster-name: dagster-eks
          requires:
            - aws-eks/create-cluster
            #- create-cluster
          filters:
             branches:
               only: [main, develop, uj_deploy]
               
      # Swap Blue/Green candidates in Docker (remember what the blue candidate was, just in case you need to rollback)
      # Manually approve cleanup
      - hold:
         type: approval
         requires:
            - eks-deploy-resources

      - aws-eks/delete-cluster:
          cluster-name: dagster-eks
          requires:
            - eks-deploy-resources
            - hold 
          filters:
             branches:
               only: [main, develop, uj_deploy]
      