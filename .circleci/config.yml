version: 2.1

# Think of orbs as libraries or packages for CircleCI
orbs:
  slack: circleci/slack@4.5.0
  aws-cli: circleci/aws-cli@2.0.6
  aws-eks: circleci/aws-eks@1.1.0
  browser-tools: circleci/browser-tools@1.2.3
  kubernetes: circleci/kubernetes@0.12.1
  docker: circleci/docker@2.0.1

# These are custom functions that I use in other jobs
commands:
  # Function 1
  notify_slack_error:
    steps:
      - slack/notify:
          event: fail
          template: basic_fail_1 # build in formating template to display failure
          mentions: "@ugochi" #if you want to target a particular person
          channel: alerts # Slack channel to display to

  # Function 2
  rollback-container-build:
    description: Rollback of Container Build to last working image
    parameters:
      # Add parameter here
      docker_image_tag:
        type: string
    steps:
      - checkout
      - run:
          name: Destroy Docker Image
          when: on_fail
          command: |
            # Your code here
            echo "Rolling back latest container to last working container"
            # Revert to previous container as the latest.
            # Delete the new container
            exit 1

  # Function 3
  cleanup-eks:
    description: Clean-up and destroy EKS cluster
    parameters:
      cluster-name:
        type: string
    steps:
      - checkout
      - run:
          name: Undeploy Applications
          when: on_fail
          command: |
            echo "Undeploying Applications"
            cd kubernetes
            kubectl delete -f dagster-service.yaml
            kubectl delete -f dagster-deployment.yaml
            exit 1
      - run: 
          name: Delete Cluster
          when: on_fail
          command: |
            echo "Deleting Cluster"
            eksctl delete cluster --name=<<parameters.cluster-name>>
            exit 1




jobs:
  lint:
    docker: 
      # This image has poetry, pyenv, pip, pipenv, and python 3.10 pre-installed
      # https://hub.docker.com/r/cimg/python
      - image: cimg/python:3.9.7  
    steps:
      - checkout
      # Use the chown command to grant CircleCI access to dependency locations
      - run: sudo chown -R circleci:circleci /usr/local/bin
      - restore_cache:
          keys:
          - v1-dependencies-{{ checksum "pyproject.toml" }}
          # fallback to using the latest cache if no exact match is found, so checksum failed
          - v1-dependencies-
      - run:
          name: Install Tools & Dependencies
          command: |
            
            # Create Environment
            python -m venv capstone
            . capstone/bin/activate
            echo -e "VIRTUAL_ENV=${VIRTUAL_ENV}\n"

            # Check linux operating system of docker container
            cat /etc/os-release

            # install tools
            make setup

            # Install python packages
            make pip-install

            make lint

      - save_cache:
          name: Save Python Virtualenv Dependencies
          key: v1-dependencies-{{ checksum "pyproject.toml" }}
          paths:
            - /usr/local/bin # Binaries of dependencies
            - capstone

      #- slack/notify # I need to add a SLACK TOKEN to enable this.
  
  # Making sure unittest pass
  test_code:
    docker: 
      # This image has poetry, pyenv, pip, pipenv, and python 3.10 pre-installed
      # https://hub.docker.com/r/cimg/python
      - image: cimg/python:3.9.7
    steps:
      - checkout
      # Use the chown command to grant CircleCI access to dependency locations
      - run: sudo chown -R circleci:circleci /usr/local/bin
      - restore_cache:
          keys:
          - v1-dependencies-{{ checksum "pyproject.toml" }}
          # fallback to using the latest cache if no exact match is found
          - v1-dependencies-
    
      - run: 
          name: Activate Environment
          command: |
            . capstone/bin/activate
            echo -e "VIRTUAL_ENV=${VIRTUAL_ENV}\n"
            pip list

      # I have to activate the virtual environment to get his to work.
      - run:
          name: Run Dagster Tests
          command: |
            . capstone/bin/activate # Why would I need to do this again?
            make test
      #- slack/notify # I need to add a SLACK TOKEN to enable this.

  # Build container and make sure browser test passes
  # More about URL servers
  build-and-deploy-image:
    docker:
      - image: cimg/python:3.9.7
        # auth:
        #     username: $DOCKER_USERNAME
        #     password: $DOCKER_ACCESS_CODE
    working_directory: ~/project/dagster
    environment:
      VERSION: v.1.<<pipeline.number>>
    steps:
      - checkout
      
      - aws-cli/install # Works only for python images, need install python 
      - docker/install-docker-tools
      - setup_remote_docker

      - run:
          name: Print Operating System
          command: |
            # Check linux operating system of docker container
            cat /etc/os-release

      - run:
          name: Load Docker image Layer Cache
          command: |
            # The following command says, if you want the command to fail due to an error at any stage 
            # when pipe(|) output of a command to another command
            set +o pipefail 
            docker load -i /caches/dagster-app.tar | true

      - run: 
          name: Build and Test Dagster Images
          command: |
            
            cd dagster

            # Your stack command code here
            echo "Building image..."

            echo "VERSION=${VERSION}"
            ls -l

            echo "DOCKER COMPOSE UP"
            docker-compose -f docker-compose-prod.yml up -d --force-recreate --build 

            echo "See images that are built"
            docker-compose images

            echo "See containers running"
            docker-compose ps

            echo "Stop Containers"
            docker-compose down
            docker-compose ps

      - run:
          name: Deploy to Docker Repository
          command: |
            cd dagster
            echo "Deploying to Docker"
            docker login -u $DOCKER_USERNAME -p $DOCKER_ACCESS_CODE
            docker-compose -f docker-compose-prod.yml push

  # Jobs for Continuous Deployment          
  initiate-cluster:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
    steps:
      - kubernetes/install
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: <<parameters.cluster-name>>
      - run:
          name: Test cluster
          command: |
            echo "@@@ Nodes"
            kubectl get nodes

            echo -e "\n@@@ Services"
            kubectl get services
      # Destroy cluster on fail
      - run:
          name: Delete Cluster
          command: |
            # This take approximately 15 minutes to complete
            # View progress on Cloudformation console
            eksctl delete cluster --name=<<parameters.cluster-name>> --wait=true
          when: on_fail

  # Reference:
  # https://circleci.com/docs/2.0/configuration-cookbook/#using-amazon-elastic-container-service-for-kubernetes-amazon-eks 
  # https://circleci.com/developer/orbs/orb/circleci/kubernetes#usage-deployment
  eks-deploy-resources:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
    working_directory: ~/project/kubernetes
    steps:
      - checkout
      - aws-cli/install
      - kubernetes/install-kubectl
      # TO DO: Create yaml files that describe the resource
      # Create Stateful Deployment Resource
      # Create Service Resource
      - run:
          name: Change Namespace
          command: |
            kubectl create ns production

      # Reference: https://stackoverflow.com/questions/49032812/how-to-pull-image-from-dockerhub-in-kubernetes
      - run: 
          name: Link DockerHub repo to EKS
          command: |
            kubectl create secret docker-registry regcred \
            --docker-username=$DOCKER_USERNAME \
            --docker-password=$DOCKER_ACCESS_CODE \
            --docker-email=$DOCKER_EMAIL \
            --namespace=production
      
      - run: 
          name: Create Service Account in Cluster
          command: |
            kubectl apply -f dagster-service-account.yaml

      - run: 
          name: Check Service Account is created
          command: |
            kubectl get sa production-service-account --namespace=dev

      - run: 
          name: Create EBS Volume for Kubernetes if it doesn't exist
          command: |
            # Check That volume doesn't exist
            #@@@ Fix!!!

            # Create Volume
            aws ec2 create-volume --availability-zone=$AWS_DEFAULT_REGION --size=10 --volume-type=gp2

      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: kubernetes/dagster-deployment.yaml # path in git directory
          resource-name: deployment/dagster-deployment.yaml # <Type of Resource>/<Name>
          show-kubectl-command: true
          watch-rollout-status: true

      - run: 
          name: Expose to the public through load balancer
          command: |
            kubectl expose deployment dagster-deployment \
            --namespace=production \
            --type=LoadBalancer \
            --name=dagster-service

            kubectl get service/dagster-service --namespace=production
      #Using your browser, navigate to the DNS endpoint specified in the EXTERNAL-IP 
      # Destroy cluster on fail
      - cleanup-eks:
          cluster-name: <<parameters.cluster-name>>
            

# Workflows
# ----------------------
workflows:
  deployment:
    jobs:
      - lint

      - test_code:
          requires: [lint] # I need the dependencies to be created first
      
      - build-and-deploy-image:
          requires: [test_code]

      - hold:
         type: approval
         requires:
            - build-and-deploy-image
         filters:
           branches: 
            ignore: [main, develop]

      # END OF CONTINUOUS INTEGRATION, START CONTINUOUS DELIVERY

      # Create EKS cluster (if not already created)
      # It also creates the default VPC for the cluster
      # Reference: https://eksctl.io/usage/vpc-networking/
      - aws-eks/create-cluster:
          cluster-name: dagster-eks-cluster
          show-eksctl-command: true
          tags: "Owner=UgochiJ, application=udacity-app, purpose=learning"
          requires:
            - build-and-deploy-image
          filters:
             branches:
               only: [main, develop, uj_deploy]

      - eks-deploy-resources:
          cluster-name: dagster-eks-cluster
          requires:
            - aws-eks/create-cluster
          filters:
             branches:
               only: [main, develop, uj_deploy]
      # Swap Blue/Green candidates in Docker (remember what the blue candidate was, just in case you need to rollback)
      # Manually approve cleanup
      - hold:
         type: approval
         requires:
            - eks-deploy-resources

      - aws-eks/delete-cluster:
          cluster-name: dagster-eks-cluster
          requires:
            - aws-eks/create-cluster
          filters:
             branches:
               only: [main, develop, uj_deploy]
      